
uniform_bool UseAutoFocus {
    header = "Focusing";
    default = true;
    display_name = "Use auto-focus";
    description = "If enabled it will make the shader focus on the point specified as 'Auto-focus point',\notherwise it will put the focus plane at the depth specified in 'Manual-focus plane'.";
}

uniform_vec2 AutoFocusPoint {
    display_name = "Auto-focus point";
    step = 0.001;
    min = vec2(0.0, 0.0);
    max = vec2(1.0, 1.0);
    description = "The X and Y coordinates of the auto-focus point. 0,0 is the upper left corner,\nand 0.5, 0.5 is at the center of the screen. Only used if 'Use auto focus' is enabled.";
    default = vec2(0.5, 0.5);
}

uniform_float AutoFocusTransitionSpeed {
    display_name = "Auto-focus transition speed";
    step = 0.01;
    min = 0.001;
    max = 1.0;
    description = "The speed the shader will transition between different focus points when using auto-focus.\n0.001 means very slow, 1.0 means instantly. Only used if 'Use auto-focus' is enabled.";
    default = 0.2;
}

uniform_float ManualFocusPlane {
    display_name = "Manual-focus plane";
    step = 0.1;
    min = 0.01;
    max = 150.0;
    description = "The depth of focal plane related to the camera when 'Use auto-focus' is off.\nOnly used if 'Use auto-focus' is disabled.";
    default = 10.0;
}

uniform_float FocalLength {
    display_name = "Focal length (mm)";
    step = 1.0;
    min = 10.0;
    max = 300.0;
    description = "Focal length of the used lens. The longer the focal length, the narrower the\ndepth of field and thus the more is out of focus. For portraits, start with 120 or 150.";
    default = 100.0;
}

uniform_float FNumber {
    display_name = "Aperture (f-number)";
    step = 0.1;
    min = 1.0;
    max = 22.0;
    description = "The f-number (also known as f-stop) to use. The higher the number, the wider\nthe depth of field, meaning the more is in-focus and thus the less is out of focus.\nFor portraits, start with 2.8.";
    default = 2.8;
}

uniform_bool ShowOutOfFocusPlaneOnMouseDown {
    header = "Focusing Overlay";
    default = true;
    display_name = "Use auto-focus";
    description = "Enables the out-of-focus plane overlay when the left mouse button is pressed down,\nwhich helps with fine-tuning the focusing.";
}

uniform_vec3 OutOfFocusPlaneColor {
    display_name = "Out-of-focus plane overlay color";
    step = 0.001;
    min = vec3(0.0, 0.0, 0.0);
    max = vec3(1.0, 1.0, 1.0);
    description = "Specifies the color of the out-of-focus planes rendered when the left-mouse button\nis pressed and 'Show out-of-focus plane on mouse down' is enabled. In (red , green, blue)";
    default = vec3(0.8, 0.8, 0.8);
}

uniform_float OutOfFocusPlaneColorTransparency {
    display_name = "Out-of-focus plane transparency";
    step = 0.05;
    min = 0.01;
    max = 1.0;
    description = "Amount of transparency of the out-of-focus planes. 0.0 is transparent, 1.0 is opaque.";
    default = 0.7;
}

uniform_vec3 FocusPlaneColor {
    display_name = "Focus plane overlay color";
    step = 0.001;
    min = vec3(0.0, 0.0, 0.0);
    max = vec3(1.0, 1.0, 1.0);
    description = "Specifies the color of the focus plane rendered when the left-mouse button\nis pressed and 'Show out-of-focus plane on mouse down' is enabled. In (red , green, blue)";
    default = vec3(0.0, 0.0, 1.0);
}

uniform_vec4 FocusCrosshairColor {
    display_name = "Focus crosshair color";
    step = 0.001;
    min = vec4(0.0, 0.0, 0.0, 0.0);
    max = vec4(1.0, 1.0, 1.0, 1.0);
    description = "Specifies the color of the crosshair for the auto-focus.\nAuto-focus must be enabled";
    default = vec4(1.0, 0.0, 1.0, 1.0);
}

uniform_float FarPlaneMaxBlur {
    header = "Blur tweaking";
    display_name = "Far plane max blur";
    step = 0.01;
    min = 0.0;
    max = 4.0;
    description = "The maximum blur a pixel can have when it has its maximum CoC in the far plane. Use this as a tweak\nto adjust the max far plane blur defined by the lens parameters. Don't use this as your primarily\nblur factor, use the lens parameters Focal Length and Aperture for that instead.";
    default = 1.0;
}

uniform_float NearPlaneMaxBlur {
    display_name = "Near plane max blur";
    step = 0.01;
    min = 0.0;
    max = 4.0;
    description = "The maximum blur a pixel can have when it has its maximum CoC in the near Plane. Use this as a tweak to\nadjust the max near plane blur defined by the lens parameters.  Don't use this as your primarily blur factor,\nuse the lens parameters Focal Length and Aperture for that instead.";
    default = 1.0;
}

uniform_float BlurQuality {
    display_name = "Overall blur quality";
    step = 1.0;
    min = 2.0;
    max = 12.0;
    description = "The number of rings to use in the disc-blur algorithm. The more rings the better\nthe blur results, but also the slower it will get.";
    default = 5.0;
}

uniform_float BokehBusyFactor {
    display_name = "Bokeh busy factor";
    step = 0.01;
    min = 0.0;
    max = 1.0;
    description = "The 'bokeh busy factor' for the blur: 0 means no busyness boost, 1.0 means extra busyness boost.";
    default = 0.5;
}

uniform_float PostBlurSmoothing {
    display_name = "Post-blur smoothing factor";
    step = 0.01;
    min = 0.0;
    max = 2.0;
    description = "The amount of post-blur smoothing blur to apply. 0.0 means no smoothing blur is applied.";
    default = 0.0;
}

uniform_float HighlightAnamorphicFactor {
    header = "Highlights";
    display_name = "Anamorphic factor";
    step = 0.01;
    min = 0.01;
    max = 1.0;
    description = "The anamorphic factor of the bokeh highlights. A value of 1.0 (default) gives perfect\ncircles, a factor of e.g. 0.1 gives thin ellipses";
    default = 1.0;
}

uniform_float HighlightAnamorphicSpreadFactor {
    header = "Highlights";
    display_name = "Anamorphic spread factor";
    step = 0.01;
    min = 0.0;
    max = 1.0;
    description = "The spread factor for the anamorphic factor. 0.0 means it's relative to the distance\nto the center of the screen, 1.0 means the factor is applied everywhere evenly,\nno matter how far the pixel is to the center of the screen.";
    default = 0.0;
}

uniform_float HighlightAnamorphicAlignmentFactor {
    display_name = "Anamorphic alignment factor";
    step = 0.01;
    min = 0.0;
    max = 1.0;
    description = "The alignment factor for the anamorphic deformation. 0.0 means you get evenly rotated\nellipses around the center of the screen, 1.0 means all bokeh highlights are\naligned vertically.";
    default = 0.0;
}

uniform_float HighlightGainFarPlane {
    header = "Highlights - Far Plane";
    display_name = "Highlight gain";
    step = 0.01;
    min = 0.0;
    max = 5.0;
    description = "The gain for highlights in the far plane. The higher the more a highlight gets\nbrighter. Tweak this in tandem with the Highlight threshold. Best results are\nachieved with bright spots in dark(er) backgrounds.";
    default = 0.5;
}

uniform_float HighlightThresholdFarPlane {
    display_name = "Highlight threshold";
    step = 0.01;
    min = 0.0;
    max = 1.0;
    description = "The threshold for the source pixels. Pixels with a luminosity above this threshold\nwill be highlighted. Raise this value to only keep the highlights you want.\nWhen highlight type is Twinkle circlets, set the threshold at 0.5 or higher\nfor blur without highlights.";
    default = 0.0;
}

uniform_float HighlightGainNearPlane {
    header = "Highlights - Near Plane";
    display_name = "Highlight gain";
    step = 0.01;
    min = 0.0;
    max = 5.0;
    description = "The gain for highlights in the near plane. The higher the more a highlight gets\nbrighter. Tweak this in tandem with the Highlight threshold. Best results are\nachieved with bright spots in dark(er) foregrounds.";
    default = 0.0;
}

uniform_float HighlightThresholdNearPlane {
    display_name = "Highlight threshold";
    step = 0.01;
    min = 0.0;
    max = 1.0;
    description = "The threshold for the source pixels. Pixels with a luminosity above this threshold\nwill be highlighted. Raise this value to only keep the highlights you want.\nWhen highlight type is Twinkle circlets, set the threshold at 0.5 or higher\nfor blur without highlights.";
    default = 0.0;
}

uniform_bool ShowCoCValues {
    header = "Advanced";
    display_name = "Show CoC values and focus plane";
    description = "Shows blur disc size (CoC) as grey (far plane) and red (near plane) and focus plane as blue";
    default = false;
}

render_target texCDCurrentFocus {
    width = 1;
    height = 1;
    internal_format = r16f;
    source_type = float;
    source_format = red;
}

render_target texCDPreviousFocus {
    width = 1;
    height = 1;
    internal_format = r16f;
    source_type = float;
    source_format = red;
}

render_target texCDCoC {
    internal_format = r16f;
    source_type = float;
    source_format = red;
    min_filter = nearest;
    mag_filter = nearest;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDCoCTileTmp {
    internal_format = r16f;
    source_type = float;
    source_format = red;
    min_filter = nearest;
    mag_filter = nearest;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDCoCTile {
    internal_format = r16f;
    source_type = float;
    source_format = red;
    min_filter = nearest;
    mag_filter = nearest;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDCoCTileNeighbor {
    internal_format = r16f;
    source_type = float;
    source_format = red;
    min_filter = nearest;
    mag_filter = nearest;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDCoCTmp1 {
    internal_format = r16f;
    source_type = float;
    source_format = red;
    width_ratio = 0.5;
    height_ratio = 0.5;
    min_filter = nearest;
    mag_filter = nearest;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDCoCBlurred {
    internal_format = rg16f;
    source_type = float;
    source_format = rg;
    width_ratio = 0.5;
    height_ratio = 0.5;
    min_filter = nearest;
    mag_filter = nearest;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDBuffer1 {
    internal_format = rgba16f;
    source_type = float;
    source_format = rgba;
    width_ratio = 0.5;
    height_ratio = 0.5;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDBuffer2 {
    internal_format = rgba16f;
    source_type = float;
    source_format = rgba;
    width_ratio = 0.5;
    height_ratio = 0.5;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDBuffer3 {
    internal_format = rgba16f;
    source_type = float;
    source_format = rgba;
    width_ratio = 0.5;
    height_ratio = 0.5;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDBuffer4 {
    internal_format = rgba16f;
    source_type = float;
    source_format = rgba;
    wrap_s = mirror;
    wrap_t = mirror;
}

render_target texCDBuffer5 {
    internal_format = rgba16f;
    source_type = float;
    source_format = rgba;
    wrap_s = mirror;
    wrap_t = mirror;
}


shared {
    float getLinearDepth(in vec2 tex)
    {
        float d = omw_GetDepth(tex);
        float ndc = d * 2.0 - 1.0;

        return omw.near * omw.far / (omw.far + ndc * (omw.near - omw.far));
    }

	void sincos(in float a, inout float s, inout float c)
	{
		s = sin(a);
		c = cos(a);
	}

	vec4 tex2Dlod(sampler2D sam, vec4 tex)
	{
		return omw_Texture2D(sam, tex.xy);
	}

	float atan2(in float x, in float y)
	{
		return atan(y, x);
	}

	#define SENSOR_SIZE			0.024		// Height of the 35mm full-frame format (36mm x 24mm)
	#define PI 					3.1415926535897932
	#define TILE_SIZE			1			// amount of pixels left/right/up/down of the current pixel. So 4 is 9x9
	#define TILE_MULTIPLY		1
	#define GROUND_TRUTH_SCREEN_WIDTH	1920.0
	#define GROUND_TRUTH_SCREEN_HEIGHT	1200.0
	#define BUFFER_SCREEN_SIZE	omw.resolution

	vec3 AccentuateWhites(vec3 fragment)
	{
		return fragment / (1.5 - clamp(fragment, 0.0, 1.49));	// accentuate 'whites'. 1.5 factor was empirically determined.
	}

	vec3 CorrectForWhiteAccentuation(vec3 fragment)
	{
		return (fragment.rgb * 1.5) / (1.0 + fragment.rgb);		// correct for 'whites' accentuation in taps. 1.5 factor was empirically determined.
	}

	// returns 2 vectors, (x,y) are up vector, (z,w) are right vector.
	// In: pixelVector which is the current pixel converted into a vector where (0,0) is the center of the screen.
	vec4 CalculateAnamorphicFactor(vec2 pixelVector)
	{
		float normalizedFactor = mix(1, HighlightAnamorphicFactor, mix(length(pixelVector * 2), 1, HighlightAnamorphicSpreadFactor));
		return vec4(0, 1 + (1-normalizedFactor), normalizedFactor, 0);
	}

	// Calculates a rotation matrix for the current pixel specified in texcoord, which can be used to rotate the bokeh shape to match
	// a distored field around the center of the screen: it rotates the anamorphic factors with this matrix so the bokeh shapes form a circle
	// around the center of the screen.
	mat2 CalculateAnamorphicRotationMatrix(vec2 texcoord)
	{
		vec2 pixelVector = normalize(texcoord - 0.5);
		float limiter = (1-HighlightAnamorphicAlignmentFactor)/2;
		pixelVector.y = clamp(pixelVector.y, -limiter, limiter);
		vec2 refVector = normalize(vec2(-0.5, 0));
		vec2 sincosFactor = vec2(0,0);
		// calculate the angle between the pixelvector and the ref vector and grab the sin/cos for that angle for the rotation matrix.
		sincosFactor.x = sin(atan2(pixelVector.y, pixelVector.x) - atan2(refVector.y, refVector.x));
		sincosFactor.y = cos(atan2(pixelVector.y, pixelVector.x) - atan2(refVector.y, refVector.x));
		return mat2(sincosFactor.y, sincosFactor.x, -sincosFactor.x, sincosFactor.y);
	}

	vec2 MorphPointOffsetWithAnamorphicDeltas(vec2 pointOffset, vec4 anamorphicFactors, mat2 anamorphicRotationMatrix)
	{
		pointOffset.x = pointOffset.x * anamorphicFactors.x + pointOffset.x*anamorphicFactors.z;
		pointOffset.y = pointOffset.y * anamorphicFactors.y + pointOffset.y*anamorphicFactors.w;
		return mul(pointOffset, anamorphicRotationMatrix);
	}

	// Gathers min CoC from a horizontal range of pixels around the pixel at texcoord, for a range of -TILE_SIZE+1 to +TILE_SIZE+1.
	// returns minCoC
	float PerformTileGatherHorizontal(sampler2D source, vec2 texcoord)
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		float tileSize = TILE_SIZE * (BUFFER_SCREEN_SIZE.x / GROUND_TRUTH_SCREEN_WIDTH);
		float minCoC = 10;
		float coc;
		vec2 coordOffset = vec2(BUFFER_PIXEL_SIZE.x, 0);
		for(float i = 0; i <= tileSize; ++i)
		{
			// TODO(wazabear): this was always fetching from mipmap level 0, texelFetch may be required?
			coc = omw_Texture2D(source, texcoord + coordOffset).r;
			minCoC = min(minCoC, coc);
			coc = omw_Texture2D(source, texcoord - coordOffset).r;
			minCoC = min(minCoC, coc);
			coordOffset.x+=BUFFER_PIXEL_SIZE.x;
		}
		return minCoC;
	}

	// Gathers min CoC from a vertical range of pixels around the pixel at texcoord from the high-res focus plane, for a range of -TILE_SIZE+1 to +TILE_SIZE+1.
	// returns min CoC
	float PerformTileGatherVertical(sampler2D source, vec2 texcoord)
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		float tileSize = TILE_SIZE * (BUFFER_SCREEN_SIZE.y / GROUND_TRUTH_SCREEN_HEIGHT);
		float minCoC = 10;
		float coc;
		vec2 coordOffset = vec2(0, BUFFER_PIXEL_SIZE.y);
		for(float i = 0; i <= tileSize; ++i)
		{
			// TODO(wazabear): this was always fetching from mipmap level 0, texelFetch may be required?
			coc = omw_Texture2D(source, texcoord + coordOffset).r;
			minCoC = min(minCoC, coc);
			coc = omw_Texture2D(source, texcoord - coordOffset).r;
			minCoC = min(minCoC, coc);
			coordOffset.y+=BUFFER_PIXEL_SIZE.y;
		}
		return minCoC;
	}

	// Gathers the min CoC of the tile at texcoord and the 8 tiles around it.
	float PerformNeighborTileGather(sampler2D source, vec2 texcoord)
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		float minCoC = 10;
		float tileSizeX = TILE_SIZE * (BUFFER_SCREEN_SIZE.x / GROUND_TRUTH_SCREEN_WIDTH);
		float tileSizeY = TILE_SIZE * (BUFFER_SCREEN_SIZE.y / GROUND_TRUTH_SCREEN_HEIGHT);
		// tile is TILE_SIZE*2+1 wide. So add that and substract that to get to neighbor tile right/left.
		// 3x3 around center.
		vec2 baseCoordOffset = vec2(BUFFER_PIXEL_SIZE.x * (tileSizeX*2+1), BUFFER_PIXEL_SIZE.x * (tileSizeY*2+1));
		for(float i=-1;i<2;i++)
		{
			for(float j=-1;j<2;j++)
			{
			// TODO(wazabear): this was always fetching from mipmap level 0, texelFetch may be required?
				vec2 coordOffset = vec2(baseCoordOffset.x * i, baseCoordOffset.y * j);
				float coc = omw_Texture2D(source, texcoord + coordOffset).r;
				minCoC = min(minCoC, coc);
			}
		}
		return minCoC;
	}

	// Calculates an RGBA fragment based on the CoC radius specified, for debugging purposes.
	// In: 	radius, the CoC radius to calculate the fragment for
	//		showInFocus, flag which will give a blue edge at the focus plane if true
	// Out:	RGBA fragment for color buffer based on the radius specified.
	vec4 GetDebugFragment(float radius, bool showInFocus)
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		vec4 toReturn = (radius/2 <= length(BUFFER_PIXEL_SIZE)) && showInFocus ? vec4(0.0, 0.0, 1.0, 1.0) : vec4(radius, radius, radius, 1.0);
		if(radius < 0)
		{
			toReturn = vec4(-radius, 0, 0, 1);
		}
		return toReturn;
	}

	// simple struct for the Focus vertex shader.
	struct VSFOCUSINFO
	{
		vec2 texcoord;
		float focusDepth;
		float focusDepthInM;
		float focusDepthInMM;
		float pixelSizeLength;
		float nearPlaneInMM;
		float farPlaneInMM;
	};

	struct VSDISCBLURINFO
	{
		vec2 texcoord;
		float numberOfRings;
		float farPlaneMaxBlurInPixels;
		float nearPlaneMaxBlurInPixels;
		float cocFactorPerPixel;
	};

	// Calculates the blur disc size for the pixel at the texcoord specified. A blur disc is the CoC size at the image plane.
	// In:	VSFOCUSINFO struct filled by the vertex shader VS_Focus
	// Out:	The blur disc size for the pixel at texcoord. Format: near plane: < 0. In-focus: 0. Far plane: > 0. Range: [-1, 1].
	float CalculateBlurDiscSize(VSFOCUSINFO focusInfo)
	{
		float pixelDepth = getLinearDepth(focusInfo.texcoord);
		float pixelDepthInM = pixelDepth * 1000.0;			// in meter

		// CoC (blur disc size) calculation based on [Lee2008]
		// CoC = ((EF / Zf - F) * (abs(Z-Zf) / Z)
		// where E is aperture size in mm, F is focal length in mm, Zf is depth of focal plane in mm, Z is depth of pixel in mm.
		// To calculate aperture in mm, we use D = F/N, where F is focal length and N is f-number
		// For the people getting confused:
		// Remember element sizes are in mm, our depth sizes are in meter, so we have to divide S1 by 1000 to get from meter -> mm. We don't have to
		// divide the elements in the 'abs(x-S1)/x' part, as the 1000.0 will then simply be muted out (as  a / (x/1000) == a * (1000/x))
		// formula: (((f*f) / N) / ((S1/1000.0) -f)) * (abs(x - S1) / x)
		// where f = FocalLength, N = FNumber, S1 = focusInfo.focusDepthInM, x = pixelDepthInM. In-lined to save on registers.
		float delta = (pixelDepthInM == 0.0) ? 1.0 : 0.0;
		float cocInMM = (((FocalLength*FocalLength) / FNumber) / ((focusInfo.focusDepthInM/1000.0) -FocalLength)) *
						(abs(pixelDepthInM - focusInfo.focusDepthInM) / (pixelDepthInM + delta));
		float toReturn = clamp(clamp(abs(cocInMM) * SENSOR_SIZE, 0.0, 1.0), 0.0, 1.0); // divide by sensor size to get coc in % of screen (or better: in sampler units)
		return (pixelDepth < focusInfo.focusDepth) ? -toReturn : toReturn;
	}

	// calculate the sample weight based on the values specified.
	float CalculateSampleWeight(float sampleRadiusInCoC, float ringDistanceInCoC)
	{
		return  clamp(sampleRadiusInCoC - ringDistanceInCoC + 0.5, 0.0, 1.0);
	}

	vec3 PostProcessBlurredFragment(vec3 fragment, float maxLuma, vec3 averageGained, float normalizationFactor)
	{
		const vec3 lumaDotWeight = vec3(0.3, 0.59, 0.11);

		float newFragmentLuma = dot(fragment, lumaDotWeight);
		averageGained.rgb = CorrectForWhiteAccentuation(averageGained.rgb);
		// increase luma to the max luma found on the gained taps. This over-boosts the luma on the averageGained, which we'll use to blend
		// together with the non-boosted fragment using the normalization factor to smoothly merge the highlights.
		averageGained.rgb *= 1+clamp(maxLuma-newFragmentLuma, 0.0, 1.0);
		fragment = (1-normalizationFactor) * fragment + normalizationFactor * averageGained.rgb;
		return fragment;
	}

	// Same as PerformDiscBlur but this time for the near plane. It's in a separate function to avoid a lot of if/switch statements as
	// the near plane blur requires different semantics.
	// Based on [Nilsson2012] and a variant of [Jimenez2014] where far/in-focus pixels are receiving a higher weight so they bleed into the near plane,
	// In:	blurInfo, the pre-calculated disc blur information from the vertex shader.
	// 		source, the source to read RGBA fragments from. Luma in alpha
	// Out: RGBA fragment for the pixel at texcoord in source, which is the blurred variant of it if it's in the near plane. A is alpha
	// to blend with.
	vec4 PerformNearPlaneDiscBlur(VSDISCBLURINFO blurInfo, sampler2D source, sampler2D _SamplerCDCoCBlurred)
	{
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		const vec3 lumaDotWeight = vec3(0.3, 0.59, 0.11);
		vec4 fragment = omw_Texture2D(source, blurInfo.texcoord);
		// r contains blurred CoC, g contains original CoC. Original is negative.
		vec2 fragmentRadii = omw_Texture2D(_SamplerCDCoCBlurred, blurInfo.texcoord).rg;
		float fragmentRadiusToUse = fragmentRadii.r;

		if(fragmentRadii.r <=0)
		{
			// the blurred CoC value is still 0, we'll never end up with a pixel that has a different value than fragment, so abort now by
			// returning the fragment we already read.
			fragment.a = 0;
			return fragment;
		}

		// use one extra ring as undersampling is really prominent in near-camera objects.
		float numberOfRings = max(blurInfo.numberOfRings, 1) + 1;
		float pointsFirstRing = 7;
		// luma is stored in alpha
		float bokehBusyFactorToUse = clamp(1.0-BokehBusyFactor, 0.0, 1.0);		// use the busy factor as an edge bias on the blur, not the highlights
		vec4 average = vec4(fragment.rgb * fragmentRadiusToUse * bokehBusyFactorToUse, bokehBusyFactorToUse);
		vec3 averageGained = AccentuateWhites(average.rgb);
		vec2 pointOffset = vec2(0,0);
		float nearPlaneBlurInPixels = blurInfo.nearPlaneMaxBlurInPixels * fragmentRadiusToUse;
		vec2 ringRadiusDeltaCoords = BUFFER_PIXEL_SIZE * (nearPlaneBlurInPixels / (numberOfRings-1));
		float pointsOnRing = pointsFirstRing;
		vec2 currentRingRadiusCoords = ringRadiusDeltaCoords;
		float maxLuma = dot(averageGained, lumaDotWeight) * -fragmentRadii.g * (1-HighlightThresholdNearPlane);
		vec4 anamorphicFactors = CalculateAnamorphicFactor(blurInfo.texcoord - 0.5); // xy are up vector, zw are right vector
		mat2 anamorphicRotationMatrix = CalculateAnamorphicRotationMatrix(blurInfo.texcoord);
		for(float ringIndex = 0; ringIndex < numberOfRings; ringIndex++)
		{
			float anglePerPoint = 6.28318530717958 / pointsOnRing;
			float angle = anglePerPoint;
			// no further weight needed, bleed all you want.
			float weight = mix(ringIndex/numberOfRings, 1, smoothstep(0, 1, bokehBusyFactorToUse));
			for(float pointNumber = 0; pointNumber < pointsOnRing; pointNumber++)
			{
				pointOffset.y = sin(angle);
				pointOffset.x = cos(angle);
				// now transform the offset vector with the anamorphic factors and rotate it accordingly to the rotation matrix, so we get a nice
				// bending around the center of the screen.
				pointOffset = MorphPointOffsetWithAnamorphicDeltas(pointOffset, anamorphicFactors, anamorphicRotationMatrix);
				vec4 tapCoords = vec4(blurInfo.texcoord + (pointOffset * currentRingRadiusCoords), 0, 0);
				vec4 tap = omw_Texture2D(source, tapCoords.xy);
				// r contains blurred CoC, g contains original CoC. Original can be negative
				vec2 sampleRadii = omw_Texture2D(_SamplerCDCoCBlurred, tapCoords.xy).rg;
				float blurredSampleRadius = sampleRadii.r;
				average.rgb += tap.rgb * weight;
				average.w += weight;
				vec3 gainedTap = AccentuateWhites(tap.rgb);
				averageGained += gainedTap * weight;
				float lumaSample = dot(gainedTap, lumaDotWeight) * clamp(blurredSampleRadius, 0.0, 1.0) * (1-HighlightThresholdNearPlane);
				maxLuma = max(maxLuma, lumaSample);
				angle+=anglePerPoint;
			}
			pointsOnRing+=pointsFirstRing;
			currentRingRadiusCoords += ringRadiusDeltaCoords;
		}

		float delta = (average.w == 0.0) ? 1.0 : 0.0;
		average.rgb/=(average.w + delta);
		float alpha = clamp((min(2.5, NearPlaneMaxBlur) + 0.4) * (fragmentRadiusToUse > 0.1 ? (fragmentRadii.g <=0 ? 2 : 1) * fragmentRadiusToUse : max(fragmentRadiusToUse, -fragmentRadii.g)), 0.0, 1.0);
		fragment.rgb = average.rgb;
		fragment.a = alpha;
#if CD_DEBUG
		if(ShowNearPlaneAlpha)
		{
			fragment = vec4(alpha, alpha, alpha, 1.0);
		}
#endif
		fragment.rgb = PostProcessBlurredFragment(fragment.rgb, maxLuma, (averageGained / (average.w + delta)), HighlightGainNearPlane);
#if CD_DEBUG
		if(ShowNearPlaneBlurred)
		{
			fragment.a = 1.0;
		}
#endif
		return fragment;
	}

	// Calculates the new RGBA fragment for a pixel at texcoord in source using a disc based blur technique described in [Jimenez2014]
	// (Though without using tiles). Blurs far plane.
	// In:	blurInfo, the pre-calculated disc blur information from the vertex shader.
	// 		source, the source buffer to read RGBA data from. A contains luma.
	// Out: RGBA fragment that's the result of the disc-blur on the pixel at texcoord in source. A contains luma of pixel.
	vec4 PerformDiscBlur(VSDISCBLURINFO blurInfo, sampler2D source, sampler2D _SamplerCDCoC)
	{
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		const vec3 lumaDotWeight = vec3(0.3, 0.59, 0.11);
		const float pointsFirstRing = 7.0; 	// each ring has a multiple of this value of sample points.
		vec4 fragment = omw_Texture2D(source, blurInfo.texcoord);
		float fragmentRadius = omw_Texture2D(_SamplerCDCoC, blurInfo.texcoord).r;
		// we'll not process near plane fragments as they're processed in a separate pass.
		if(fragmentRadius < 0 || blurInfo.farPlaneMaxBlurInPixels <=0)
		{
			// near plane fragment, will be done in near plane pass
			return fragment;
		}
		// luma is stored in alpha
		float bokehBusyFactorToUse = clamp(1.0-BokehBusyFactor, 0.0, 1.0)-0.2;		// use the busy factor as an edge bias on the blur, not the highlights
		vec4 average = vec4(fragment.rgb * fragmentRadius * bokehBusyFactorToUse, bokehBusyFactorToUse);
		vec3 averageGained = AccentuateWhites(average.rgb);
		vec2 pointOffset = vec2(0,0);
		vec2 ringRadiusDeltaCoords =  (BUFFER_PIXEL_SIZE * blurInfo.farPlaneMaxBlurInPixels * fragmentRadius) / blurInfo.numberOfRings;
		vec2 currentRingRadiusCoords = ringRadiusDeltaCoords;
		float cocPerRing = (fragmentRadius * FarPlaneMaxBlur) / blurInfo.numberOfRings;
		float pointsOnRing = pointsFirstRing;
		float maxLuma = dot(averageGained.rgb, lumaDotWeight) * fragmentRadius * (1-HighlightThresholdFarPlane);
		vec4 anamorphicFactors = CalculateAnamorphicFactor(blurInfo.texcoord - 0.5); // xy are up vector, zw are right vector
		mat2 anamorphicRotationMatrix = CalculateAnamorphicRotationMatrix(blurInfo.texcoord);
		for(float ringIndex = 0; ringIndex < blurInfo.numberOfRings; ringIndex++)
		{
			float anglePerPoint = 6.28318530717958 / pointsOnRing;
			float angle = anglePerPoint;
			float ringWeight = mix(ringIndex/blurInfo.numberOfRings, 1, bokehBusyFactorToUse);
			float ringDistance = cocPerRing * ringIndex;
			for(float pointNumber = 0; pointNumber < pointsOnRing; pointNumber++)
			{
				pointOffset.y = sin(angle);
				pointOffset.x = cos(angle);
				// now transform the offset vector with the anamorphic factors and rotate it accordingly to the rotation matrix, so we get a nice
				// bending around the center of the screen.
				pointOffset = MorphPointOffsetWithAnamorphicDeltas(pointOffset, anamorphicFactors, anamorphicRotationMatrix);
				vec4 tapCoords = vec4(blurInfo.texcoord + (pointOffset * currentRingRadiusCoords), 0, 0);
				float sampleRadius = omw_Texture2D(_SamplerCDCoC, tapCoords.xy).r;
				vec4 tap = omw_Texture2D(source, tapCoords.xy);
				float weight = ((sampleRadius >=0.0) ? 1.0 : 0.0) * ringWeight * CalculateSampleWeight(sampleRadius * FarPlaneMaxBlur, ringDistance);
				average.rgb += tap.rgb * weight;
				average.w += weight;
				vec3 gainedTap = sampleRadius >= 0 ? AccentuateWhites(tap.rgb) : tap.rgb;
				averageGained += gainedTap * weight;
				float lumaSample = clamp(dot(gainedTap, lumaDotWeight) * sampleRadius * (1-HighlightThresholdFarPlane), 0.0, 1.0);
				maxLuma = sampleRadius > 0 ? max(maxLuma, lumaSample) : maxLuma;
				angle+=anglePerPoint;
			}
			pointsOnRing+=pointsFirstRing;
			currentRingRadiusCoords += ringRadiusDeltaCoords;
		}
		float delta = (average.w==0.0) ? 1.0 : 0.0;
		fragment.rgb = average.rgb / (average.w + delta);
		fragment.rgb = PostProcessBlurredFragment(fragment.rgb, maxLuma, (averageGained / (average.w + delta)), HighlightGainFarPlane);
		return fragment;
	}

	// Performs a small blur to the out of focus areas using a lower amount of rings. Additionally it calculates the luma of the fragment into alpha
	// and makes sure the fragment post-blur has the maximum luminosity from the taken samples to preserve harder edges on highlights.
	// In:	blurInfo, the pre-calculated disc blur information from the vertex shader.
	// 		source, the source buffer to read RGBA data from
	// Out: RGBA fragment that's the result of the disc-blur on the pixel at texcoord in source. A contains luma of RGB.
	vec4 PerformPreDiscBlur(VSDISCBLURINFO blurInfo, sampler2D source, sampler2D _SamplerCDCoC)
	{
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		float radiusFactor = 1.0/max(blurInfo.numberOfRings, 1);
		float pointsFirstRing = max(blurInfo.numberOfRings-3, 2); 	// each ring has a multiple of this value of sample points.
		vec4 fragment = omw_Texture2D(source, blurInfo.texcoord);
		float signedFragmentRadius = omw_Texture2D(_SamplerCDCoC, blurInfo.texcoord).x * radiusFactor;
		float absoluteFragmentRadius = abs(signedFragmentRadius);
		bool isNearPlaneFragment = signedFragmentRadius < 0;
		float blurFactorToUse = isNearPlaneFragment ? NearPlaneMaxBlur : FarPlaneMaxBlur;
		// Substract 2 as we blur on a smaller range. Don't limit the rings based on radius here, as that will kill the pre-blur.
		float numberOfRings = max(blurInfo.numberOfRings-2, 1);
		vec4 average = absoluteFragmentRadius == 0 ? fragment : vec4(fragment.rgb * absoluteFragmentRadius, absoluteFragmentRadius);
		vec2 pointOffset = vec2(0,0);
		// pre blur blurs near plane fragments with near plane samples and far plane fragments with far plane samples [Jimenez2014].
		vec2 ringRadiusDeltaCoords = BUFFER_PIXEL_SIZE
												* ((isNearPlaneFragment ? blurInfo.nearPlaneMaxBlurInPixels : blurInfo.farPlaneMaxBlurInPixels) *  absoluteFragmentRadius)
												* rcp((numberOfRings-1) + ((numberOfRings==1.0) ? 1.0 : 0.0));
		float pointsOnRing = pointsFirstRing;
		vec2 currentRingRadiusCoords = ringRadiusDeltaCoords;
		float cocPerRing = (signedFragmentRadius * blurFactorToUse) / numberOfRings;
		for(float ringIndex = 0; ringIndex < numberOfRings; ringIndex++)
		{
			float anglePerPoint = 6.28318530717958 / pointsOnRing;
			float angle = anglePerPoint;
			float ringDistance = cocPerRing * ringIndex;
			for(float pointNumber = 0; pointNumber < pointsOnRing; pointNumber++)
			{
				sincos(angle, pointOffset.y, pointOffset.x);
				vec4 tapCoords = vec4(blurInfo.texcoord + (pointOffset * currentRingRadiusCoords), 0, 0);
				float signedSampleRadius = omw_Texture2D(_SamplerCDCoC, tapCoords.xy).x * radiusFactor;
				float absoluteSampleRadius = abs(signedSampleRadius);
				float isSamePlaneAsFragment = (((signedSampleRadius > 0 && !isNearPlaneFragment) || (signedSampleRadius <= 0 && isNearPlaneFragment))) ? 1.0 : 0.0;
				float weight = CalculateSampleWeight(absoluteSampleRadius * blurFactorToUse, ringDistance) * isSamePlaneAsFragment *
								((absoluteFragmentRadius - absoluteSampleRadius < 0.001) ? 1.0 : 0.0);
				average.rgb += (omw_Texture2D(source, tapCoords.xy).rgb) * weight;
				average.w += weight;
				angle+=anglePerPoint;
			}
			pointsOnRing+=pointsFirstRing;
			currentRingRadiusCoords += ringRadiusDeltaCoords;
		}
		fragment.rgb = average.rgb/(average.w + ((average.w==0.0) ? 1.0 : 0.0));
		// store luma of new rgb in alpha so we don't need to calculate it again.
		fragment.a = dot(fragment.rgb, vec3(0.3, 0.59, 0.11));
		return fragment;
	}

	// Function to obtain the blur disc radius from the source sampler specified and optionally flatten it to zero. Used to blur the blur disc radii using a
	// separated gaussian blur function.
	// In:	source, the source to read the blur disc radius value to process from
	//		texcoord, the coordinate of the pixel which blur disc radius value we have to process
	//		flattenToZero, flag which if true will make this function convert a blur disc radius value bigger than 0 to 0.
	//		Radii bigger than 0 are in the far plane and we only want near plane radii in our blurred buffer.
	// Out: processed blur disc radius for the pixel at texcoord in source.
	float GetBlurDiscRadiusFromSource(sampler2D source, vec2 texcoord, bool flattenToZero)
	{
		float coc = omw_Texture2D(source, texcoord).r;
		// we're only interested in negative coc's (near plane). All coc's in focus/far plane are flattened to 0. Return the
		// absolute value of the coc as we're working with positive blurred CoCs (as the sign is no longer needed)
		return (flattenToZero && coc >= 0) ? 0 : abs(coc);
	}

	// Performs a single value gaussian blur pass in 1 direction (18 taps). Based on Ioxa's Gaussian blur shader. Used for near plane CoC blur.
	// Used on tiles so not expensive.
	// In:	source, the source sampler to read blur disc radius values to blur from
	//		texcoord, the coordinate of the pixel to blur the blur disc radius for
	// 		offsetWeight, a weight to multiple the coordinate with, containing typically the x or y value of the pixel size
	//		flattenToZero, a flag to pass on to the actual blur disc radius read function to make sure in this pass the positive values are squashed to 0.
	// 					   This flag is needed as the gaussian blur is used separably here so the second pass should not look for positive blur disc radii
	//					   as all values are already positive (due to the first pass).
	// Out: the blurred value for the blur disc radius of the pixel at texcoord. Greater than 0 if the original CoC is in the near plane, 0 otherwise.
	float PerformSingleValueGaussianBlur(sampler2D source, vec2 texcoord, vec2 offsetWeight, bool flattenToZero)
	{
		float offset[18] = { 0.0, 1.4953705027, 3.4891992113, 5.4830312105, 7.4768683759, 9.4707125766, 11.4645656736, 13.4584295168, 15.4523059431, 17.4461967743, 19.4661974725, 21.4627427973, 23.4592916956, 25.455844494, 27.4524015179, 29.4489630909, 31.445529535, 33.4421011704 };
		float weight[18] = { 0.033245, 0.0659162217, 0.0636705814, 0.0598194658, 0.0546642566, 0.0485871646, 0.0420045997, 0.0353207015, 0.0288880982, 0.0229808311, 0.0177815511, 0.013382297, 0.0097960001, 0.0069746748, 0.0048301008, 0.0032534598, 0.0021315311, 0.0013582974 };

		float coc = GetBlurDiscRadiusFromSource(source, texcoord, flattenToZero);
		coc *= weight[0];

		vec2 factorToUse = offsetWeight * NearPlaneMaxBlur * 0.8;
		for(int i = 1; i < 18; ++i)
		{
			vec2 coordOffset = factorToUse * offset[i];
			float weightSample = weight[i];
			coc += GetBlurDiscRadiusFromSource(source, texcoord + coordOffset, flattenToZero) * weightSample;
			coc += GetBlurDiscRadiusFromSource(source, texcoord - coordOffset, flattenToZero) * weightSample;
		}

		return clamp(coc, 0.0, 1.0);
	}

	// Performs a full fragment (RGBA) gaussian blur pass in 1 direction (16 taps). Based on Ioxa's Gaussian blur shader.
	// Will skip any pixels which are in-focus. It will also apply the pixel's blur disc radius to further limit the blur range for near-focused pixels.
	// In:	source, the source sampler to read RGBA values to blur from
	//		texcoord, the coordinate of the pixel to blur.
	// 		offsetWeight, a weight to multiple the coordinate with, containing typically the x or y value of the pixel size
	// Out: the blurred fragment(RGBA) for the pixel at texcoord.
	vec4 PerformFullFragmentGaussianBlur(sampler2D source, vec2 texcoord, vec2 offsetWeight, sampler2D _SamplerCDCoC)
	{
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		float offset[6] = { 0.0, 1.4584295168, 3.40398480678, 5.3518057801, 7.302940716, 9.2581597095 };
		float weight[6] = { 0.13298, 0.23227575, 0.1353261595, 0.0511557427, 0.01253922, 0.0019913644 };
		const vec3 lumaDotWeight = vec3(0.3, 0.59, 0.11);

		float coc = omw_Texture2D(_SamplerCDCoC, texcoord).r;
		vec4 fragment = omw_Texture2D(source, texcoord);
		float fragmentLuma = dot(fragment.rgb, lumaDotWeight);
		vec4 originalFragment = fragment;
		float absoluteCoC = abs(coc);
		float lengthPixelSize = length(BUFFER_PIXEL_SIZE);
		if(absoluteCoC < 0.2 || PostBlurSmoothing < 0.01 || fragmentLuma < 0.3)
		{
			// in focus or postblur smoothing isn't enabled or not really a highlight, ignore
			return fragment;
		}
		fragment.rgb *= weight[0];
		vec2 factorToUse = offsetWeight * PostBlurSmoothing;
		for(int i = 1; i < 6; ++i)
		{
			vec2 coordOffset = factorToUse * offset[i];
			float weightSample = weight[i];
			float sampleCoC = omw_Texture2D(_SamplerCDCoC, texcoord + coordOffset).r;
			float maskFactor = (abs(sampleCoC) < 0.2) ? 1.0 : 0.0;		// mask factor to avoid near/in focus bleed.
			fragment.rgb += (originalFragment.rgb * maskFactor * weightSample) +
							(omw_Texture2D(source, texcoord + coordOffset).rgb * (1-maskFactor) * weightSample);
			sampleCoC = omw_Texture2D(_SamplerCDCoC, texcoord - coordOffset).r;
			maskFactor = (abs(sampleCoC) < 0.2) ? 1.0 : 0.0;
			fragment.rgb += (originalFragment.rgb * maskFactor * weightSample) +
							(omw_Texture2D(source, texcoord - coordOffset).rgb * (1-maskFactor) * weightSample);
		}
		return clamp(fragment, 0.0, 1.0);
	}

	// Functions which fills the passed in struct with focus data. This code is factored out to be able to call it either from a vertex shader
	// (in d3d10+) or from a pixel shader (d3d9) to work around compilation issues in reshade.
	void FillFocusInfoData(inout VSFOCUSINFO toFill, sampler2D _SamplerCDCurrentFocus)
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy;

		// Reshade depth buffer ranges from 0.0->1.0, where 1.0 is 1000 in world units. All camera element sizes are in mm, so we state 1 in world units is
		// 1 meter. This means to calculate from the linearized depth buffer value to meter we have to multiply by 1000.
		// Manual focus value is already in meter (well, sort of. This differs per game so we silently assume it's meter), so we first divide it by
		// 1000 to make it equal to a depth value read from the depth linearized depth buffer.
		// Read from sampler on current focus which is a 1x1 texture filled with the actual depth value of the focus point to use.
		toFill.focusDepth = tex2Dlod(_SamplerCDCurrentFocus, vec4(0.5, 0.5, 0, 0)).r;
		toFill.focusDepthInM = toFill.focusDepth * 1000.0; 		// km to m
		toFill.focusDepthInMM = toFill.focusDepthInM * 1000.0; 	// m to mm
		toFill.pixelSizeLength = length(BUFFER_PIXEL_SIZE);

		// // HyperFocal calculation, see https://photo.stackexchange.com/a/33898. Useful to calculate the edges of the depth of field area
		float hyperFocal = (FocalLength * FocalLength) / (FNumber * SENSOR_SIZE);
		float hyperFocalFocusDepthFocus = (hyperFocal * toFill.focusDepthInMM);
		toFill.nearPlaneInMM = hyperFocalFocusDepthFocus / (hyperFocal + (toFill.focusDepthInMM - FocalLength));	// in mm
		toFill.farPlaneInMM = hyperFocalFocusDepthFocus / (hyperFocal - (toFill.focusDepthInMM - FocalLength));		// in mm
	}
}

fragment DetermineCurrentFocus(target=texCDCurrentFocus, rt1=texCDPreviousFocus) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		vec2 autoFocusPointToUse = vec2(0.5, 0.5);//UseMouseDrivenAutoFocus ? MouseCoords * BUFFER_PIXEL_SIZE : AutoFocusPoint;
		omw_FragColor.r = UseAutoFocus ? mix(omw_Texture2D(texCDPreviousFocus, vec2(0.5, 0.5)).r, getLinearDepth(autoFocusPointToUse), AutoFocusTransitionSpeed) : (ManualFocusPlane / 1000.0);
	}
}

fragment CopyCurrentFocus(target=texCDPreviousFocus, rt1=texCDCurrentFocus) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		omw_FragColor.r = texture(texCDCurrentFocus, vec2(0.5, 0.5)).r;
	}
}

vertex CalculateCoC(rt1=texCDCurrentFocus) {
	#if OMW_USE_BINDINGS
		omw_In vec2 omw_Vertex;
	#endif

	omw_Out vec2 omw_TexCoord;

	omw_Out flat float focusDepth;
	omw_Out flat float focusDepthInM;
	omw_Out flat float focusDepthInMM;
	omw_Out flat float pixelSizeLength;
	omw_Out flat float nearPlaneInMM;
	omw_Out flat float farPlaneInMM;

	void main()
	{
		omw_Position = vec4(omw_Vertex.xy, 0.0, 1.0);
		omw_TexCoord = omw_Position.xy * 0.5 + 0.5;

		VSFOCUSINFO focusInfo;
		FillFocusInfoData(focusInfo, texCDCurrentFocus);

		focusDepth = focusInfo.focusDepth;
		focusDepthInM = focusInfo.focusDepthInM;
		focusDepthInMM = focusInfo.focusDepthInMM;
		pixelSizeLength = focusInfo.pixelSizeLength;
		nearPlaneInMM = focusInfo.nearPlaneInMM;
		farPlaneInMM = focusInfo.farPlaneInMM;
	}
}

fragment CalculateCoC(target=texCDCoC) {
	omw_In vec2 omw_TexCoord;

	omw_In flat float focusDepth;
	omw_In flat float focusDepthInM;
	omw_In flat float focusDepthInMM;
	omw_In flat float pixelSizeLength;
	omw_In flat float nearPlaneInMM;
	omw_In flat float farPlaneInMM;

	void main()
	{
		VSFOCUSINFO focusInfo;
		focusInfo.texcoord = omw_TexCoord;
		focusInfo.focusDepth = focusDepth;
		focusInfo.focusDepthInM = focusDepthInM;
		focusInfo.focusDepthInMM = focusDepthInMM;
		focusInfo.pixelSizeLength = pixelSizeLength;
		focusInfo.nearPlaneInMM = nearPlaneInMM;
		focusInfo.farPlaneInMM = farPlaneInMM;

		omw_FragColor.r = CalculateBlurDiscSize(focusInfo);
	}
}

fragment CoCTile1(target=texCDCoCTileTmp, rt1=texCDCoC) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		omw_FragColor.r = PerformTileGatherHorizontal(texCDCoC, omw_TexCoord);
	}
}

fragment CoCTile2(rt1=texCDCoCTile, rt1=texCDCoCTileTmp) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		omw_FragColor.r = PerformTileGatherVertical(texCDCoCTileTmp, omw_TexCoord);
	}
}

fragment CoCTileNeighbor(rt1=texCDCoCTileNeighbor, rt1=texCDCoCTile) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		omw_FragColor.r = PerformNeighborTileGather(texCDCoCTile, omw_TexCoord);
	}
}

fragment CoCBlur1(rt1=texCDCoCTmp1, rt1=texCDCoCTileNeighbor) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		vec2 BUFFER_PIXEL_SIZE = 1.0 / (omw.resolution * 0.5);
		omw_FragColor.r = PerformSingleValueGaussianBlur(texCDCoCTileNeighbor, omw_TexCoord, 
												  vec2(BUFFER_PIXEL_SIZE.x * (BUFFER_SCREEN_SIZE.x/GROUND_TRUTH_SCREEN_WIDTH), 0.0), true);
	}
}

fragment CoCBlur2(rt1=texCDCoCBlurred, rt1=texCDCoCTileNeighbor, rt2=texCDCoCTmp1) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		vec2 BUFFER_PIXEL_SIZE = 1.0 / (omw.resolution * 0.5);

		// from tmp1 to tmp2. Merge original CoC into g.
		omw_FragColor.rg = vec2(PerformSingleValueGaussianBlur(texCDCoCTmp1, omw_TexCoord, 
														 vec2(0.0, BUFFER_PIXEL_SIZE.y * (BUFFER_SCREEN_SIZE.y/GROUND_TRUTH_SCREEN_HEIGHT)), false), 
						  omw_Texture2D(texCDCoCTileNeighbor, omw_TexCoord).x);
	}
}

vertex PreBlur {
	#if OMW_USE_BINDINGS
		omw_In vec2 omw_Vertex;
	#endif

	omw_Out vec2 omw_TexCoord;

	omw_Out flat float numberOfRings;
	omw_Out flat float farPlaneMaxBlurInPixels;
	omw_Out flat float nearPlaneMaxBlurInPixels;
	omw_Out flat float cocFactorPerPixel;

	void main()
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy * 0.5;

		omw_Position = vec4(omw_Vertex.xy, 0.0, 1.0);
		omw_TexCoord = omw_Position.xy * 0.5 + 0.5;

		numberOfRings = round(BlurQuality);
		float pixelSizeLength = length(BUFFER_PIXEL_SIZE);
		farPlaneMaxBlurInPixels = (FarPlaneMaxBlur / 100.0) / pixelSizeLength;
		nearPlaneMaxBlurInPixels = (NearPlaneMaxBlur / 100.0) / pixelSizeLength;
		cocFactorPerPixel = length(BUFFER_PIXEL_SIZE) * farPlaneMaxBlurInPixels;	// not needed for near plane.
	}
}

fragment PreBlur(target=texCDBuffer1, rt1=texCDCoC) {
    omw_In vec2 omw_TexCoord;

	omw_In flat float numberOfRings;
	omw_In flat float farPlaneMaxBlurInPixels;
	omw_In flat float nearPlaneMaxBlurInPixels;
	omw_In flat float cocFactorPerPixel;

    void main()
    {
		VSDISCBLURINFO blurInfo;

		blurInfo.texcoord = omw_TexCoord;
		blurInfo.numberOfRings = numberOfRings;
		blurInfo.farPlaneMaxBlurInPixels = farPlaneMaxBlurInPixels;
		blurInfo.nearPlaneMaxBlurInPixels = nearPlaneMaxBlurInPixels;
		blurInfo.cocFactorPerPixel = cocFactorPerPixel;

		omw_FragColor = PerformPreDiscBlur(blurInfo, omw_SamplerLastShader, texCDCoC);
    }
}

vertex BokehBlur {
	#if OMW_USE_BINDINGS
		omw_In vec2 omw_Vertex;
	#endif

	omw_Out vec2 omw_TexCoord;

	omw_Out flat float numberOfRings;
	omw_Out flat float farPlaneMaxBlurInPixels;
	omw_Out flat float nearPlaneMaxBlurInPixels;
	omw_Out flat float cocFactorPerPixel;

	void main()
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy * 0.5;

		omw_Position = vec4(omw_Vertex.xy, 0.0, 1.0);
		omw_TexCoord = omw_Position.xy * 0.5 + 0.5;

		numberOfRings = round(BlurQuality);
		float pixelSizeLength = length(BUFFER_PIXEL_SIZE);
		farPlaneMaxBlurInPixels = (FarPlaneMaxBlur / 100.0) / pixelSizeLength;
		nearPlaneMaxBlurInPixels = (NearPlaneMaxBlur / 100.0) / pixelSizeLength;
		cocFactorPerPixel = length(BUFFER_PIXEL_SIZE) * farPlaneMaxBlurInPixels;	// not needed for near plane.
	}
}

fragment BokehBlur(target=texCDBuffer2, rt1=texCDBuffer1, rt2=texCDCoC) {
    omw_In vec2 omw_TexCoord;

	omw_In flat float numberOfRings;
	omw_In flat float farPlaneMaxBlurInPixels;
	omw_In flat float nearPlaneMaxBlurInPixels;
	omw_In flat float cocFactorPerPixel;

    void main()
    {
		VSDISCBLURINFO blurInfo;

		blurInfo.texcoord = omw_TexCoord;
		blurInfo.numberOfRings = numberOfRings;
		blurInfo.farPlaneMaxBlurInPixels = farPlaneMaxBlurInPixels;
		blurInfo.nearPlaneMaxBlurInPixels = nearPlaneMaxBlurInPixels;
		blurInfo.cocFactorPerPixel = cocFactorPerPixel;

		omw_FragColor = PerformDiscBlur(blurInfo, texCDBuffer1, texCDCoC);
    }
}

vertex NearBokehBlur {
	#if OMW_USE_BINDINGS
		omw_In vec2 omw_Vertex;
	#endif

	omw_Out vec2 omw_TexCoord;

	omw_Out flat float numberOfRings;
	omw_Out flat float farPlaneMaxBlurInPixels;
	omw_Out flat float nearPlaneMaxBlurInPixels;
	omw_Out flat float cocFactorPerPixel;

	void main()
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy * 0.5;

		omw_Position = vec4(omw_Vertex.xy, 0.0, 1.0);
		omw_TexCoord = omw_Position.xy * 0.5 + 0.5;

		numberOfRings = round(BlurQuality);
		float pixelSizeLength = length(BUFFER_PIXEL_SIZE);
		farPlaneMaxBlurInPixels = (FarPlaneMaxBlur / 100.0) / pixelSizeLength;
		nearPlaneMaxBlurInPixels = (NearPlaneMaxBlur / 100.0) / pixelSizeLength;
		cocFactorPerPixel = length(BUFFER_PIXEL_SIZE) * farPlaneMaxBlurInPixels;	// not needed for near plane.
	}
}

fragment NearBokehBlur(target=texCDBuffer1, rt1=texCDBuffer2, rt2=texCDCoCBlurred) {
    omw_In vec2 omw_TexCoord;

	omw_In flat float numberOfRings;
	omw_In flat float farPlaneMaxBlurInPixels;
	omw_In flat float nearPlaneMaxBlurInPixels;
	omw_In flat float cocFactorPerPixel;

    void main()
    {
		VSDISCBLURINFO blurInfo;

		blurInfo.texcoord = omw_TexCoord;
		blurInfo.numberOfRings = numberOfRings;
		blurInfo.farPlaneMaxBlurInPixels = farPlaneMaxBlurInPixels;
		blurInfo.nearPlaneMaxBlurInPixels = nearPlaneMaxBlurInPixels;
		blurInfo.cocFactorPerPixel = cocFactorPerPixel;

		omw_FragColor = PerformPreDiscBlur(blurInfo, texCDBuffer2, texCDCoCBlurred);
    }
}

fragment TentFilter(target=texCDBuffer3, rt1=texCDBuffer2) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		// TODO(wazabear): this is relative to render target, luckily RT uses full dimensions :)
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution.xy * 0.5;

		vec4 coord = BUFFER_PIXEL_SIZE.xyxy * vec4(1, 1, -1, 0);
		vec4 average;
		average = omw_Texture2D(texCDBuffer2, omw_TexCoord - coord.xy);
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord - coord.wy) * 2;
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord - coord.zy);
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord + coord.zw) * 2;
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord) * 4;
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord + coord.xw) * 2;
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord + coord.zy);
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord + coord.wy) * 2;
		average += omw_Texture2D(texCDBuffer2, omw_TexCoord + coord.xy);
		omw_FragColor = average / 16;
	}
}

fragment Combiner(target=texCDBuffer4, rt1=texCDBuffer1, rt2=texCDBuffer3, rt3=texCDCoC) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		// first blend far plane with original buffer, then near plane on top of that. 
		vec4 originalFragment = omw_GetLastShader(omw_TexCoord);
		vec4 farFragment = omw_Texture2D(texCDBuffer3, omw_TexCoord);
		vec4 nearFragment = omw_Texture2D(texCDBuffer1, omw_TexCoord);
		// multiply with far plane max blur so if we need to have 0 blur we get full res 
		float realCoC = omw_Texture2D(texCDCoC, omw_TexCoord).r * clamp(0, 1, FarPlaneMaxBlur);
		// all CoC's > 0.1 are full far fragment, below that, we're going to blend. This avoids shimmering far plane without the need of a 
		// 'magic' number to boost up the alpha.
		float blendFactor = (realCoC > 0.1) ? 1.0 : smoothstep(0, 1, (realCoC / 0.1));
		omw_FragColor = mix(originalFragment, farFragment, blendFactor);
		omw_FragColor.rgb = mix(omw_FragColor.rgb, nearFragment.rgb, nearFragment.a * ((NearPlaneMaxBlur != 0) ? 1.0 : 0.0));
#if CD_DEBUG
		if(ShowOnlyFarPlaneBlurred)
		{
			omw_FragColor = farFragment;
		}
#endif
		omw_FragColor.a = 1.0;
	}
}

fragment PostSmoothing1(rt1=texCDBuffer4, rt2=texCDCoC) {
	omw_In vec2 omw_TexCoord;

	void main()
	{
		vec2 BUFFER_PIXEL_SIZE = omw.rcpResolution;
		omw_FragColor = PerformFullFragmentGaussianBlur(texCDBuffer4, omw_TexCoord, vec2(BUFFER_PIXEL_SIZE.x, 0.0), texCDCoC);
	}
}

technique {
    passes = DetermineCurrentFocus,
		     CopyCurrentFocus,
			 CalculateCoC,
			 CoCTile1,
			 CoCTile2,
			 CoCTileNeighbor,
			 CoCBlur1,
			 CoCBlur2,
			 PreBlur,
			 BokehBlur,
			 NearBokehBlur,
			 TentFilter,
			 Combiner,
			 PostSmoothing1;
    description = "Adapted Cinematic Depth of Field shader";
    author = "Frans Bouma, aka Otis / Infuse Project (Otis_Inf)";
    version = "1.0";
    flags = Disable_Interiors;
}
